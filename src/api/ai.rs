use crate::api::util::ai_model_from_header;
use crate::biz::authentication::jwt::UserUuid;
use crate::biz::subscription::ops::{fetch_current_subscription, record_usage};
use crate::biz::workspace::subscription_plan_limits::PlanLimits;
use crate::state::AppState;
use shared_entity::dto::subscription_dto::UsageRecordRequest;
use shared_entity::dto::subscription_dto::UsageType;

use actix_web::web::{Data, Json};
use actix_web::{web, HttpRequest, HttpResponse, Scope};
use app_error::AppError;
use appflowy_ai_client::dto::{
  CalculateSimilarityParams, LocalAIConfig, ModelList, SimilarityResponse, TranslateRowParams,
  TranslateRowResponse,
};
use appflowy_ai_client::{AIModel, AIModelInfo, AvailableModelsResponse, ChatRequestParams};

use futures_util::{stream, StreamExt, TryStreamExt};

use database::ai_usage::{get_workspace_ai_usage_this_month, increment_ai_usage};
use serde::Deserialize;
use shared_entity::dto::ai_dto::{
  CompleteTextParams, SummarizeRowData, SummarizeRowParams, SummarizeRowResponse,
};
use shared_entity::dto::billing_dto::SubscriptionPlan;
use shared_entity::response::AppResponse;
use uuid::Uuid;

use tracing::{error, info, instrument, trace, warn};

pub fn ai_completion_scope() -> Scope {
  web::scope("/api/ai")
    // å…¬å¼€æ¥å£ï¼ˆæ— éœ€è®¤è¯ï¼Œæ— éœ€workspace_idï¼‰
    .service(web::resource("/chat/models").route(web::get().to(list_chat_models_handler)))
    .service(web::resource("/chat/session").route(web::post().to(public_chat_session_handler)))
    .service(web::resource("/file/upload").route(web::post().to(upload_file_handler)))
    // workspaceç›¸å…³æ¥å£
    .service(web::scope("/{workspace_id}")
      .service(web::resource("/complete/stream").route(web::post().to(stream_complete_text_handler)))
      .service(web::resource("/v2/complete/stream").route(web::post().to(stream_complete_v2_handler)))
      .service(web::resource("/chat/stream").route(web::post().to(stream_chat_handler)))
      .service(web::resource("/summarize_row").route(web::post().to(summarize_row_handler)))
      .service(web::resource("/translate_row").route(web::post().to(translate_row_handler)))
      .service(web::resource("/local/config").route(web::get().to(local_ai_config_handler)))
      .service(
        web::resource("/calculate_similarity").route(web::post().to(calculate_similarity_handler)),
      )
      .service(web::resource("/model/list").route(web::get().to(model_list_handler)))
    )
}

async fn stream_complete_text_handler(
  _user_uuid: UserUuid,
  workspace_id: web::Path<Uuid>,
  state: Data<AppState>,
  payload: Json<CompleteTextParams>,
  req: HttpRequest,
) -> actix_web::Result<HttpResponse> {
  let workspace_id = workspace_id.into_inner();
  let ai_model = ai_model_from_header(&req);
  let params = payload.into_inner();
  
  // Check AI usage limits
  if let Err(err) = check_ai_usage_limit(&state, &workspace_id).await {
    return Ok(
      HttpResponse::Ok()
        .content_type("text/event-stream")
        .streaming(stream::once(async move { Err(err) })),
    );
  }
  
  state.metrics.ai_metrics.record_total_completion_count(1);

  if let Some(prompt_id) = params
    .metadata
    .as_ref()
    .and_then(|metadata| metadata.prompt_id.as_ref())
  {
    state
      .metrics
      .ai_metrics
      .record_prompt_usage_count(prompt_id, 1);
  }

  match state
    .ai_client
    .stream_completion_text(params, ai_model)
    .await
  {
    Ok(stream) => {
      // Increment AI usage count after successful request
      if let Err(e) = increment_ai_usage(&state.pg_pool, &workspace_id).await {
        error!("Failed to increment AI usage: {:?}", e);
      }
      
      Ok(
        HttpResponse::Ok()
          .content_type("text/event-stream")
          .streaming(stream.map_err(AppError::from)),
      )
    },
    Err(err) => Ok(
      HttpResponse::Ok()
        .content_type("text/event-stream")
        .streaming(stream::once(async move {
          Err(AppError::AIServiceUnavailable(err.to_string()))
        })),
    ),
  }
}

async fn stream_complete_v2_handler(
  _user_uuid: UserUuid,
  workspace_id: web::Path<Uuid>,
  state: Data<AppState>,
  payload: Json<CompleteTextParams>,
  req: HttpRequest,
) -> actix_web::Result<HttpResponse> {
  let workspace_id = workspace_id.into_inner();
  let ai_model = ai_model_from_header(&req);
  let params = payload.into_inner();
  
  // Check AI usage limits
  if let Err(err) = check_ai_usage_limit(&state, &workspace_id).await {
    return Ok(
      HttpResponse::Ok()
        .content_type("text/event-stream")
        .streaming(stream::once(async move { Err(err) })),
    );
  }
  
  state.metrics.ai_metrics.record_total_completion_count(1);

  match state.ai_client.stream_completion_v2(params, ai_model).await {
    Ok(stream) => {
      // Increment AI usage count after successful request
      if let Err(e) = increment_ai_usage(&state.pg_pool, &workspace_id).await {
        error!("Failed to increment AI usage: {:?}", e);
      }
      
      Ok(
        HttpResponse::Ok()
          .content_type("text/event-stream")
          .streaming(stream.map_err(AppError::from)),
      )
    },
    Err(err) => Ok(
      HttpResponse::Ok()
        .content_type("text/event-stream")
        .streaming(stream::once(async move {
          Err(AppError::AIServiceUnavailable(err.to_string()))
        })),
    ),
  }
}
#[instrument(level = "debug", skip(state, payload), err)]
async fn summarize_row_handler(
  state: Data<AppState>,
  payload: Json<SummarizeRowParams>,
  req: HttpRequest,
) -> actix_web::Result<Json<AppResponse<SummarizeRowResponse>>> {
  let params = payload.into_inner();
  match params.data {
    SummarizeRowData::Identity { .. } => {
      return Err(AppError::InvalidRequest("Identity data is not supported".to_string()).into());
    },
    SummarizeRowData::Content(content) => {
      if content.is_empty() {
        return Ok(
          AppResponse::Ok()
            .with_data(SummarizeRowResponse {
              text: "No content".to_string(),
            })
            .into(),
        );
      }

      state.metrics.ai_metrics.record_total_summary_row_count(1);
      let ai_model = ai_model_from_header(&req);
      let result = state.ai_client.summarize_row(&content, ai_model).await;
      let resp = match result {
        Ok(resp) => SummarizeRowResponse { text: resp.text },
        Err(err) => {
          error!("Failed to summarize row: {:?}", err);
          SummarizeRowResponse {
            text: "No content".to_string(),
          }
        },
      };

      Ok(AppResponse::Ok().with_data(resp).into())
    },
  }
}

#[instrument(level = "debug", skip(state, payload), err)]
async fn translate_row_handler(
  state: web::Data<AppState>,
  payload: web::Json<TranslateRowParams>,
  req: HttpRequest,
) -> actix_web::Result<Json<AppResponse<TranslateRowResponse>>> {
  let params = payload.into_inner();
  let ai_model = ai_model_from_header(&req);
  state.metrics.ai_metrics.record_total_translate_row_count(1);
  match state.ai_client.translate_row(params.data, ai_model).await {
    Ok(resp) => Ok(AppResponse::Ok().with_data(resp).into()),
    Err(err) => {
      error!("Failed to translate row: {:?}", err);
      Ok(
        AppResponse::Ok()
          .with_data(TranslateRowResponse::default())
          .into(),
      )
    },
  }
}

#[derive(Deserialize, Debug)]
struct ConfigQuery {
  platform: String,
  app_version: Option<String>,
}

#[instrument(level = "debug", skip_all, err)]
async fn local_ai_config_handler(
  state: web::Data<AppState>,
  query: web::Query<ConfigQuery>,
) -> actix_web::Result<Json<AppResponse<LocalAIConfig>>> {
  let query = query.into_inner();
  trace!("query ai configuration: {:?}", query);
  let platform = match query.platform.as_str() {
    "macos" => "macos",
    "linux" => "ubuntu",
    "ubuntu" => "ubuntu",
    "windows" => "windows",
    _ => {
      return Err(AppError::InvalidRequest("Invalid platform".to_string()).into());
    },
  };

  let config = state
    .ai_client
    .get_local_ai_config(platform, query.app_version)
    .await
    .map_err(|err| AppError::AIServiceUnavailable(err.to_string()))?;
  Ok(AppResponse::Ok().with_data(config).into())
}

/// Helper function to check if AI usage is within limits
async fn check_ai_usage_limit(state: &AppState, workspace_id: &Uuid) -> Result<(), AppError> {
  // Get workspace subscription plan
  let workspace = database::workspace::select_workspace(&state.pg_pool, workspace_id).await?;
  let plan = SubscriptionPlan::try_from(workspace.workspace_type)
    .map_err(|e| AppError::Internal(anyhow::anyhow!("Invalid workspace type: {}", e)))?;
  
  let limits = PlanLimits::from_plan(&plan);
  
  // If AI is unlimited, no need to check
  if limits.ai_unlimited {
    return Ok(());
  }
  
  // Get current AI usage this month
  let current_usage = get_workspace_ai_usage_this_month(&state.pg_pool, workspace_id).await?;
  
  // Check if usage limit is exceeded
  if !limits.can_use_ai(current_usage) {
    return Err(AppError::PlanLimitExceeded(format!(
      "AI response limit exceeded. Plan: {:?}, Current: {}, Limit: {}. Please upgrade your subscription.",
      plan, current_usage, limits.ai_responses_limit
    )));
  }
  
  Ok(())
}

#[instrument(level = "debug", skip_all, err)]
async fn calculate_similarity_handler(
  state: web::Data<AppState>,
  payload: web::Json<CalculateSimilarityParams>,
) -> actix_web::Result<Json<AppResponse<SimilarityResponse>>> {
  let params = payload.into_inner();

  let response = state
    .ai_client
    .calculate_similarity(params)
    .await
    .map_err(|err| AppError::AIServiceUnavailable(err.to_string()))?;
  Ok(AppResponse::Ok().with_data(response).into())
}

#[instrument(level = "debug", skip_all, err)]
async fn model_list_handler(
  state: web::Data<AppState>,
) -> actix_web::Result<Json<AppResponse<ModelList>>> {
  let model_list = state
    .ai_client
    .get_model_list()
    .await
    .map_err(|err| AppError::AIServiceUnavailable(err.to_string()))?;
  Ok(AppResponse::Ok().with_data(model_list).into())
}

/// æµå¼AIèŠå¤©æ¥å£ (ä½¿ç”¨ç¬¬ä¸‰æ–¹AIæä¾›å•†)
#[instrument(level = "debug", skip(state, payload), err)]
async fn stream_chat_handler(
  user_uuid: UserUuid,
  workspace_id: web::Path<Uuid>,
  state: Data<AppState>,
  payload: Json<ChatRequestParams>,
) -> actix_web::Result<HttpResponse> {
  let workspace_id = workspace_id.into_inner();
  let params = payload.into_inner();
  
  trace!(
    "Chat request from user {} for workspace {}, message length: {}", 
    *user_uuid,
    workspace_id,
    params.message.len()
  );
  
  // 1. æ£€æŸ¥ AI ä½¿ç”¨é™é¢
  if let Err(err) = check_ai_usage_limit(&state, &workspace_id).await {
    error!("AI usage limit exceeded for workspace {}: {:?}", workspace_id, err);
    return Ok(
      HttpResponse::PaymentRequired()
        .json(serde_json::json!({
          "code": "AI_LIMIT_EXCEEDED",
          "message": err.to_string(),
        }))
    );
  }
  
  // 2. ç¡®å®šä½¿ç”¨çš„æ¨¡å‹
  let model = if let Some(model_id) = &params.preferred_model {
    AIModel::from_str(model_id).unwrap_or(AIModel::DeepSeek)
  } else {
    // æ ¹æ®è®¢é˜…è®¡åˆ’é€‰æ‹©é»˜è®¤æ¨¡å‹
    let workspace = database::workspace::select_workspace(&state.pg_pool, &workspace_id).await?;
    let plan = SubscriptionPlan::try_from(workspace.workspace_type)
      .map_err(|e| AppError::Internal(anyhow::anyhow!("Invalid workspace type: {}", e)))?;
    
    match plan {
      SubscriptionPlan::Free | SubscriptionPlan::Basic => AIModel::DeepSeek,
      SubscriptionPlan::Pro => AIModel::QwenTurbo,
      SubscriptionPlan::Team | SubscriptionPlan::AiMax => AIModel::QwenMax,
      _ => AIModel::DeepSeek,
    }
  };
  
  trace!("Using AI model: {:?}", model);
  
  // 3. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
  if !state.chat_client.is_model_available(model) {
    error!("AI model {:?} is not available (API key not configured)", model);
    return Ok(
      HttpResponse::ServiceUnavailable()
        .json(serde_json::json!({
          "code": "MODEL_UNAVAILABLE",
          "message": format!("AI model {:?} is not available", model),
        }))
    );
  }
  
  // 4. å¦‚æœæœ‰å›¾ç‰‡ï¼Œä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ï¼ˆè±†åŒ…éœ€è¦URLæ ¼å¼ï¼‰
  let mut params = params;
  if params.has_images && params.images.is_some() {
    if let Some(qiniu_client) = &state.qiniu_client {
      let mut image_urls = Vec::new();
      
      if let Some(images) = &params.images {
        for (idx, image_data) in images.iter().enumerate() {
          // åˆ¤æ–­æ˜¯å¦å·²ç»æ˜¯URL
          if image_data.starts_with("http://") || image_data.starts_with("https://") {
            // å·²ç»æ˜¯URLï¼Œç›´æ¥ä½¿ç”¨
            image_urls.push(image_data.clone());
          } else {
            // æ˜¯base64æ•°æ®ï¼Œéœ€è¦ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
            match base64::Engine::decode(&base64::engine::general_purpose::STANDARD, image_data) {
              Ok(image_bytes) => {
                // ç”Ÿæˆå¯¹è±¡å­˜å‚¨key
                let timestamp = std::time::SystemTime::now()
                  .duration_since(std::time::UNIX_EPOCH)
                  .unwrap()
                  .as_millis();
                let object_key = format!(
                  "ai-chat-images/{}/{}-{}.jpg",
                  workspace_id.to_string(),
                  timestamp,
                  idx
                );
                
                // ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
                match qiniu_client.upload_file(&object_key, image_bytes, "image/jpeg").await {
                  Ok(url) => {
                    info!("Image {} uploaded to Qiniu Cloud: {}", idx, url);
                    image_urls.push(url);
                  },
                  Err(e) => {
                    error!("Failed to upload image {} to Qiniu Cloud: {}", idx, e);
                    // å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œä¿ç•™base64ï¼ˆå¯¹äºä¸éœ€è¦URLçš„æ¨¡å‹ï¼‰
                    image_urls.push(image_data.clone());
                  }
                }
              },
              Err(e) => {
                error!("Failed to decode base64 image {}: {}", idx, e);
                // è§£ç å¤±è´¥ï¼Œè·³è¿‡æ­¤å›¾ç‰‡
              }
            }
          }
        }
      }
      
      // æ›´æ–°paramsä¸­çš„å›¾ç‰‡æ•°æ®ä¸ºURL
      if !image_urls.is_empty() {
        params.images = Some(image_urls);
        trace!("Updated {} image(s) to URL format", params.images.as_ref().unwrap().len());
      } else {
        warn!("No valid images after processing");
      }
    } else {
      warn!("Qiniu Cloud not configured, images will be sent as base64 (may not work with Doubao)");
    }
  }
  
  // 5. è°ƒç”¨ ChatClient è¿›è¡Œæµå¼èŠå¤©
  match state.chat_client.stream_chat(&params, model).await {
    Ok(stream) => {
      // 6. å¼‚æ­¥å¢åŠ  AI ä½¿ç”¨é‡
      let pg_pool = state.pg_pool.clone();
      let ws_id = workspace_id;
      tokio::spawn(async move {
        if let Err(e) = increment_ai_usage(&pg_pool, &ws_id).await {
          error!("Failed to increment AI usage: {:?}", e);
        }
      });
      
      // 7. è¿”å›æµå¼å“åº”
      Ok(
        HttpResponse::Ok()
          .content_type("text/event-stream")
          .streaming(stream.map(|result| {
            result.map_err(|e| actix_web::error::ErrorInternalServerError(e))
          }))
      )
    },
    Err(err) => {
      error!("AI chat service error: {:?}", err);
      Ok(
        HttpResponse::InternalServerError()
          .json(serde_json::json!({
            "code": "AI_SERVICE_ERROR",
            "message": format!("AI service error: {}", err),
          }))
      )
    },
  }
}

/// è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨ (å…¬å¼€æ¥å£ï¼Œæ— éœ€è®¤è¯ï¼Œæ— éœ€å‚æ•°)
#[instrument(level = "debug", skip(state), err)]
async fn list_chat_models_handler(
  state: Data<AppState>,
) -> actix_web::Result<Json<AppResponse<AvailableModelsResponse>>> {
  trace!("List all available chat models (public endpoint, no auth required)");
  
  // è·å–æ‰€æœ‰å®é™…é…ç½®çš„å¯ç”¨æ¨¡å‹
  let available_models = state.chat_client.get_available_models();
  
  trace!("Available models from ChatClient: {:?}", available_models);
  
  // è¿”å›æ‰€æœ‰é…ç½®å¥½çš„æ¨¡å‹ï¼Œä¸åŸºäºè®¢é˜…è®¡åˆ’
  let mut models = vec![];
  
  if available_models.contains(&AIModel::DeepSeek) {
    models.push(AIModelInfo {
      id: "deepseek-chat".to_string(),
      name: "DeepSeek".to_string(),
      description: "é«˜æ€§èƒ½å¯¹è¯æ¨¡å‹".to_string(),
      is_default: true,
    });
  }
  
  if available_models.contains(&AIModel::QwenTurbo) {
    models.push(AIModelInfo {
      id: "qwen-turbo".to_string(),
      name: "é€šä¹‰åƒé—® Turbo".to_string(),
      description: "é˜¿é‡Œäº‘é€šä¹‰åƒé—®å¿«é€Ÿç‰ˆ".to_string(),
      is_default: false,
    });
  }
  
  if available_models.contains(&AIModel::QwenMax) {
    models.push(AIModelInfo {
      id: "qwen-max".to_string(),
      name: "é€šä¹‰åƒé—® Max".to_string(),
      description: "é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ——èˆ°ç‰ˆ".to_string(),
      is_default: false,
    });
  }
  
  if available_models.contains(&AIModel::Doubao) {
    models.push(AIModelInfo {
      id: "doubao".to_string(),
      name: "è±†åŒ…".to_string(),
      description: "å­—èŠ‚è·³åŠ¨è±†åŒ…".to_string(),
      is_default: false,
    });
  }
  
  Ok(AppResponse::Ok().with_data(AvailableModelsResponse {
    models,
    current_plan: "public".to_string(), // å…¬å¼€æ¥å£ï¼Œæ— è®¢é˜…è®¡åˆ’
  }).into())
}

/// æ£€æŸ¥ç”¨æˆ·å‰©ä½™AIè°ƒç”¨æ¬¡æ•°
async fn check_user_ai_remaining(
  state: &AppState,
  user_uuid: &UserUuid,
) -> Result<i64, AppError> {
  // 1. è·å–ç”¨æˆ· uid
  let uid = state.user_cache.get_user_uid(user_uuid).await?;
  
  // 2. è·å–ç”¨æˆ·å½“å‰è®¢é˜…ä¿¡æ¯
  let subscription_response = fetch_current_subscription(&state.pg_pool, uid).await?;
  
  // 3. è·å–å‰©ä½™æ¬¡æ•°
  let remaining = subscription_response.usage.ai_chat_remaining_this_month;
  
  // 4. å¦‚æœä¸º Noneï¼Œè¡¨ç¤ºæ— é™åˆ¶ï¼Œè¿”å›æœ€å¤§å€¼ï¼›å¦åˆ™è¿”å›å‰©ä½™æ¬¡æ•°
  match remaining {
    Some(count) => Ok(count),
    None => Ok(i64::MAX), // æ— é™åˆ¶
  }
}

/// è®°å½•AIèŠå¤©ä½¿ç”¨æƒ…å†µ
async fn record_ai_chat_usage(
  state: &AppState,
  user_uuid: &UserUuid,
) -> Result<(), AppError> {
  let uid = state.user_cache.get_user_uid(user_uuid).await?;
  
  record_usage(
    &state.pg_pool,
    uid,
    UsageRecordRequest {
      usage_type: UsageType::AiChat,
      usage_count: 1,
      usage_date: None, // ä½¿ç”¨å½“å‰æ—¥æœŸ
    },
  )
  .await?;
  
  Ok(())
}

/// èŠå¤©ä¼šè¯æ¥å£ (éœ€è¦JWTè®¤è¯ï¼Œæ ¹æ®è®¢é˜…è®¡åˆ’é™åˆ¶ä½¿ç”¨æ¬¡æ•°)
#[instrument(level = "debug", skip(state, payload, user_uuid), err)]
async fn public_chat_session_handler(
  user_uuid: UserUuid,
  state: Data<AppState>,
  payload: Json<ChatRequestParams>,
) -> actix_web::Result<HttpResponse> {
  let params = payload.into_inner();
  
  info!(
    "ğŸ” [AIä¼šè¯] æ”¶åˆ°ç”¨æˆ·è¯·æ±‚ - user: {}, message_len: {}, model: {:?}", 
    *user_uuid,
    params.message.len(),
    params.preferred_model
  );
  info!(
    "ğŸ” [AIä¼šè¯] è¯·æ±‚å‚æ•° - has_images: {}, images_count: {}, has_files: {}, thinking: {}, search: {}", 
    params.has_images,
    params.images.as_ref().map(|v| v.len()).unwrap_or(0),
    params.has_files,
    params.enable_thinking,
    params.enable_web_search
  );
  
  // 1. æ£€æŸ¥ç”¨æˆ·å‰©ä½™AIè°ƒç”¨æ¬¡æ•°
  let remaining = match check_user_ai_remaining(&state, &user_uuid).await {
    Ok(count) => count,
    Err(AppError::RecordNotFound(_)) => {
      error!("User {} has no active subscription", *user_uuid);
      return Ok(
        HttpResponse::NotFound()
          .json(serde_json::json!({
            "code": "SUBSCRIPTION_NOT_FOUND",
            "message": "æŠ±æ­‰ï¼Œæ‚¨è¿˜æœªå¼€å¯è®¢é˜…è®¡åˆ’ï¼Œé—®AIåŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚",
          }))
      );
    },
    Err(err) => {
      error!("Failed to check AI remaining for user {}: {:?}", *user_uuid, err);
      return Ok(
        HttpResponse::InternalServerError()
          .json(serde_json::json!({
            "code": "INTERNAL_ERROR",
            "message": format!("æ£€æŸ¥è®¢é˜…ä¿¡æ¯å¤±è´¥: {}", err),
          }))
      );
    },
  };
  
  // 2. æ£€æŸ¥å‰©ä½™æ¬¡æ•°æ˜¯å¦è¶³å¤Ÿï¼ˆ>= 1ï¼‰
  if remaining < 1 {
    error!("User {} AI limit exceeded, remaining: {}", *user_uuid, remaining);
    return Ok(
      HttpResponse::PaymentRequired()
        .json(serde_json::json!({
          "code": "AI_LIMIT_EXCEEDED",
          "message": format!("AIè°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œï¼Œå‰©ä½™æ¬¡æ•°ï¼š{}ï¼Œè¯·å‡çº§è®¢é˜…æˆ–è´­ä¹°è¡¥å……åŒ…", remaining),
        }))
    );
  }
  
  trace!("User {} has {} remaining AI calls", *user_uuid, remaining);
  
  // 3. ç¡®å®šä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¿…é¡»æŒ‡å®šï¼Œæˆ–ä½¿ç”¨é»˜è®¤çš„ DeepSeekï¼‰
  let model = if let Some(model_id) = &params.preferred_model {
    AIModel::from_str(model_id).unwrap_or(AIModel::DeepSeek)
  } else {
    AIModel::DeepSeek // é»˜è®¤ä½¿ç”¨ DeepSeek
  };
  
  trace!("Using AI model: {:?}", model);
  
  // 4. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
  if !state.chat_client.is_model_available(model) {
    error!("AI model {:?} is not available (API key not configured)", model);
    return Ok(
      HttpResponse::ServiceUnavailable()
        .json(serde_json::json!({
          "code": "MODEL_UNAVAILABLE",
          "message": format!("AI model {:?} is not available", model),
        }))
    );
  }
  
  // 5. å¦‚æœæœ‰å›¾ç‰‡ï¼Œä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ï¼ˆè±†åŒ…éœ€è¦URLæ ¼å¼ï¼‰
  let mut params = params;
  if params.has_images && params.images.is_some() {
    info!("ğŸ“¸ [AIä¼šè¯] æ£€æµ‹åˆ°å›¾ç‰‡æ•°æ®ï¼Œå‡†å¤‡å¤„ç†...");
    if let Some(qiniu_client) = &state.qiniu_client {
      info!("âœ… [AIä¼šè¯] ä¸ƒç‰›äº‘å®¢æˆ·ç«¯å·²é…ç½®ï¼Œå¼€å§‹ä¸Šä¼ å›¾ç‰‡");
      let mut image_urls = Vec::new();
      
      if let Some(images) = &params.images {
        for (idx, image_data) in images.iter().enumerate() {
          // åˆ¤æ–­æ˜¯å¦å·²ç»æ˜¯URL
          if image_data.starts_with("http://") || image_data.starts_with("https://") {
            // å·²ç»æ˜¯URLï¼Œç›´æ¥ä½¿ç”¨
            image_urls.push(image_data.clone());
          } else {
            // æ˜¯base64æ•°æ®ï¼Œéœ€è¦ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
            match base64::Engine::decode(&base64::engine::general_purpose::STANDARD, image_data) {
              Ok(image_bytes) => {
                // ç”Ÿæˆå¯¹è±¡å­˜å‚¨key
                let timestamp = std::time::SystemTime::now()
                  .duration_since(std::time::UNIX_EPOCH)
                  .unwrap()
                  .as_millis();
                let object_key = format!(
                  "ai-chat-images/{}/{}-{}.jpg",
                  user_uuid.to_string(),
                  timestamp,
                  idx
                );
                
                info!("ğŸ”„ [AIä¼šè¯] å¼€å§‹ä¸Šä¼ å›¾ç‰‡ {} åˆ°ä¸ƒç‰›äº‘ï¼Œkey: {}", idx, object_key);
                
                // ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
                match qiniu_client.upload_file(&object_key, image_bytes, "image/jpeg").await {
                  Ok(url) => {
                    info!("âœ… [AIä¼šè¯] å›¾ç‰‡ {} ä¸Šä¼ æˆåŠŸï¼URL: {}", idx, url);
                    image_urls.push(url);
                  },
                  Err(e) => {
                    error!("âŒ [AIä¼šè¯] å›¾ç‰‡ {} ä¸Šä¼ å¤±è´¥: {}", idx, e);
                    // å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œä¿ç•™base64ï¼ˆå¯¹äºä¸éœ€è¦URLçš„æ¨¡å‹ï¼‰
                    image_urls.push(image_data.clone());
                  }
                }
              },
              Err(e) => {
                error!("âŒ [AIä¼šè¯] å›¾ç‰‡ {} base64è§£ç å¤±è´¥: {}", idx, e);
                // è§£ç å¤±è´¥ï¼Œè·³è¿‡æ­¤å›¾ç‰‡
              }
            }
          }
        }
      }
      
      // æ›´æ–°paramsä¸­çš„å›¾ç‰‡æ•°æ®ä¸ºURL
      if !image_urls.is_empty() {
        info!("âœ… [AIä¼šè¯] å›¾ç‰‡å¤„ç†å®Œæˆï¼Œå…± {} å¼ å›¾ç‰‡è½¬æ¢ä¸ºURL", image_urls.len());
        for (i, url) in image_urls.iter().enumerate() {
          info!("   å›¾ç‰‡ {}: {}", i, url);
        }
        params.images = Some(image_urls);
      } else {
        error!("âŒ [AIä¼šè¯] å›¾ç‰‡å¤„ç†åæ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡æ•°æ®");
      }
    } else {
      error!("âŒ [AIä¼šè¯] ä¸ƒç‰›äº‘å®¢æˆ·ç«¯æœªé…ç½®ï¼æ— æ³•ä¸Šä¼ å›¾ç‰‡");
      error!("   è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼šQINIU_ENABLED, QINIU_ACCESS_KEY, QINIU_SECRET_KEY");
    }
  } else {
    info!("â„¹ï¸ [AIä¼šè¯] æœ¬æ¬¡è¯·æ±‚ä¸åŒ…å«å›¾ç‰‡");
  }
  
  // 6. è°ƒç”¨ ChatClient è¿›è¡Œæµå¼èŠå¤©
  match state.chat_client.stream_chat(&params, model).await {
    Ok(stream) => {
      // 7. å¼‚æ­¥è®°å½•ä½¿ç”¨æƒ…å†µï¼ˆä¸é˜»å¡å“åº”ï¼‰
      let state_clone = state.clone();
      let user_uuid_clone = user_uuid.clone();
      tokio::spawn(async move {
        if let Err(e) = record_ai_chat_usage(&state_clone, &user_uuid_clone).await {
          error!("Failed to record AI chat usage for user {}: {:?}", *user_uuid_clone, e);
        }
      });
      
      // 8. è¿”å›æµå¼å“åº”
      Ok(
        HttpResponse::Ok()
          .content_type("text/event-stream")
          .streaming(stream.map(|result| {
            result.map_err(|e| actix_web::error::ErrorInternalServerError(e))
          }))
      )
    },
    Err(err) => {
      error!("AI chat service error: {:?}", err);
      Ok(
        HttpResponse::InternalServerError()
          .json(serde_json::json!({
            "code": "AI_SERVICE_ERROR",
            "message": format!("AI service error: {}", err),
          }))
      )
    },
  }
}

/// æ–‡ä»¶ä¸Šä¼ å¤„ç†æ¥å£ï¼ˆéœ€è¦JWTè®¤è¯ï¼‰
/// æ”¯æŒå¤šç§æ–‡ä»¶ç±»å‹çš„ä¸Šä¼ å’Œé¢„å¤„ç†
#[instrument(level = "debug", skip(state, payload, user_uuid), err)]
async fn upload_file_handler(
  user_uuid: UserUuid,
  state: Data<AppState>,
  mut payload: actix_multipart::Multipart,
) -> actix_web::Result<HttpResponse> {
  use futures_util::StreamExt;
  
  trace!("File upload request from user {}", *user_uuid);
  
  let mut files_processed = Vec::new();
  
  while let Some(item) = payload.next().await {
    let mut field = item.map_err(|e| {
      error!("Failed to read multipart field: {}", e);
      actix_web::error::ErrorBadRequest(format!("Invalid multipart data: {}", e))
    })?;
    
    let filename = field
      .content_disposition()
      .and_then(|cd| cd.get_filename())
      .unwrap_or("unnamed_file")
      .to_string();
    
    trace!("Processing file: {}", filename);
    
    // è¯»å–æ–‡ä»¶æ•°æ®
    let mut file_data = Vec::new();
    while let Some(chunk) = field.next().await {
      let data = chunk.map_err(|e| {
        error!("Failed to read file chunk: {}", e);
        actix_web::error::ErrorBadRequest(format!("Failed to read file: {}", e))
      })?;
      file_data.extend_from_slice(&data);
    }
    
    let file_size = file_data.len() as i64;
    
    // æ–‡ä»¶å¤§å°é™åˆ¶: 20MB
    if file_size > 20 * 1024 * 1024 {
      return Ok(
        HttpResponse::PayloadTooLarge()
          .json(serde_json::json!({
            "code": "FILE_TOO_LARGE",
            "message": format!("æ–‡ä»¶ {} è¶…è¿‡20MBé™åˆ¶", filename),
          }))
      );
    }
    
    // æå–æ–‡ä»¶ç±»å‹
    let file_type = filename
      .split('.')
      .last()
      .unwrap_or("unknown")
      .to_lowercase();
    
    trace!("File type: {}, size: {} bytes", file_type, file_size);
    
    // å°è¯•ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘ï¼ˆå¦‚æœå·²å¯ç”¨ï¼‰
    let file_url = if let Some(qiniu_client) = &state.qiniu_client {
      trace!("Uploading file to Qiniu Cloud: {}", filename);
      
      // æ¨æ–­Content-Type
      let content_type = infra::qiniu_client::infer_content_type(&filename);
      
      // ç”Ÿæˆå¯¹è±¡å­˜å‚¨key
      let object_key = infra::qiniu_client::QiniuClient::generate_ai_file_key(
        "ai-session",  // æš‚æ—¶ä½¿ç”¨å›ºå®šworkspace_idï¼Œåç»­å¯ä»¥æ”¹ä¸ºå®é™…çš„
        &user_uuid.to_string(),
        &filename,
      );
      
      // ä¸Šä¼ åˆ°ä¸ƒç‰›äº‘
      match qiniu_client.upload_file(&object_key, file_data.clone(), &content_type).await {
        Ok(url) => {
          info!("File uploaded to Qiniu Cloud successfully: {}", url);
          Some(url)
        },
        Err(e) => {
          error!("Failed to upload file to Qiniu Cloud: {}", e);
          None  // å¤±è´¥æ—¶è¿”å›Noneï¼Œåç»­å¯ä»¥fallbackåˆ°base64
        }
      }
    } else {
      trace!("Qiniu Cloud not enabled, file will be processed locally");
      None
    };
    
    // æ ¹æ®æ–‡ä»¶ç±»å‹è¿›è¡Œé¢„å¤„ç†
    let (content_type, content_data) = match file_type.as_str() {
      // æ–‡æœ¬æ–‡ä»¶ï¼šç›´æ¥è½¬æ¢ä¸ºæ–‡æœ¬
      "txt" | "md" | "markdown" | "json" | "xml" | "html" | "css" | "js" 
      | "ts" | "jsx" | "tsx" | "py" | "rs" | "go" | "java" | "c" | "cpp" 
      | "h" | "hpp" | "sh" | "bash" | "yaml" | "yml" | "toml" | "ini" 
      | "log" | "csv" | "sql" => {
        match String::from_utf8(file_data.clone()) {
          Ok(text) => {
            info!("Text file processed: {} ({} chars)", filename, text.len());
            ("text", Some(text))
          },
          Err(_) => ("base64", Some(base64::Engine::encode(&base64::engine::general_purpose::STANDARD, &file_data)))
        }
      },
      // å›¾ç‰‡æ–‡ä»¶ï¼šå¦‚æœæœ‰URLåˆ™ä½¿ç”¨URLï¼Œå¦åˆ™ä½¿ç”¨base64
      "jpg" | "jpeg" | "png" | "gif" | "webp" | "bmp" | "svg" => {
        if file_url.is_some() {
          ("url", None)  // å¦‚æœæœ‰URLï¼Œä¸éœ€è¦ä¼ è¾“æ–‡ä»¶å†…å®¹
        } else {
          ("base64", Some(base64::Engine::encode(&base64::engine::general_purpose::STANDARD, &file_data)))
        }
      },
      // PDFå’ŒOfficeæ–‡æ¡£ï¼šä¼˜å…ˆä½¿ç”¨URL
      "pdf" | "docx" | "xlsx" | "pptx" => {
        if file_url.is_some() {
          warn!("Document {} uploaded to Qiniu Cloud", filename);
          ("url", None)
        } else {
          warn!("Document {} will be sent as base64 (Qiniu not available)", filename);
          ("base64", Some(base64::Engine::encode(&base64::engine::general_purpose::STANDARD, &file_data)))
        }
      },
      _ => {
        if file_url.is_some() {
          ("url", None)
        } else {
          ("base64", Some(base64::Engine::encode(&base64::engine::general_purpose::STANDARD, &file_data)))
        }
      }
    };
    
    let mut file_info = serde_json::json!({
      "file_name": filename,
      "file_type": file_type,
      "file_size": file_size,
      "content_type": content_type,
      "status": "processed",
    });
    
    // æ·»åŠ URLæˆ–content
    if let Some(url) = file_url {
      file_info["url"] = serde_json::json!(url);
    } else if let Some(content) = content_data {
      file_info["content"] = serde_json::json!(content);
    }
    
    files_processed.push(file_info);
  }
  
  info!("Successfully processed {} file(s)", files_processed.len());
  
  Ok(
    HttpResponse::Ok()
      .json(serde_json::json!({
        "code": "SUCCESS",
        "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ",
        "files": files_processed,
      }))
  )
}
